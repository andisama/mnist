{
    "nbformat_minor": 2, 
    "cells": [
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Author: Andi Sama\n# Organization: Sinergi Wahana Gemilang\n#   a Value Added Distributor in Jakarta, Indonesia\n# Created: June 18, 2018\n# Last modified:\n#   - June 19, 2018\n#     * Add a few more information during training by modifying code in network_asm.py\n#       (% on classification rate & elapsed time per epoch + total elapsed time for all epochs)\n#     * Add a few more information during training by modifying code in mnist_loader_asm.py\n#       (loaded data sizes)\n#   - June 21, 2018\n#     * Apply cross-entropy on cost function (previously: use quadratic cost) to improve accuracy\n#     * Apply Mini-batch gradient descent (previously: just Stochastic Gradient Descent)\n#     * Add monitor_elapsed_time flag in network2_asm.py\n#     * Draw plot for training cost, evaluation cost against # of epoch\n#     * Use Gaussian distributions with mean 0 and standard deviation 1 over the square root\n#       of the number of weights connecting to the same neuron for network initialization\n#       (previously: Gaussian distribution without square root)\n#   - June 23, 2018\n#     * Use regularization - lambda \n#     * Visualization of mnist dataset\n#   - June 24, 2018\n#       Add predict() function use existing function load() network after save()\n#       => vanilla version done\n#   - June 24, 2018\n#     * use mnist testing dataset to predict (now still using training data)\n#   - June 25-26, 2018\n#     * migrate to IBM Watson Studio (on cloud)\n#       - upload all files to IBM object storage\n#       - get all files to working directory by using IBM boto3 api\n#       - convert code from python 2.7 to 3.5 (print function, cPickle handler, xrange)\n#   - June 28, 2018\n#     retrain with lambda = 0 (no regularization, for article - for SWG Insights Q4 2018)\n#   - July 9-12, 2018\n#     change framework to keras (change MNIST input to numpy.ndarray)\n#   - July 14-15, 2018\n#     use Conv2D with Keras (change environment to 2 vCPU and 8GB RAM <prev 1vCPU, 4GB>)\n# Topic: Beginning Deep Learning (computer vision)\n# Purpose: Recognizing handwritten digits 0-9 in 3 steps\n#   - 1. Prepare datasets (MNIST, modified nist database)\n#   - 2. Train, Validate on datasets to generate deep learning model (architecture, weights)\n#   - 3. Predict new data based on generated model with testing data \n# Type of Neural Network: Supervised Learning with shallow neural network\n#   Dataset: mnist\n#     - original training dataset (60,000): handwritten digits from 250 persons (2 groups)\n#       further then divided to be 50,000 for training dataset and 10,000 for validation dataset\n#     - testing dataset (10,000): handwritten digits from another set of 250 persons (2 groups)\n# Hardware & Software platforms:\n#   - environment: cygwin on Windows, on Thinkpad T450 (i7 4 vCPUs without GPUs, 16 GB RAM)\n#   - programming language: python (v2.7)\n#   - deep learning framework: none\n#   - libraries: sys, pandas, numpy, math, matplotlib, botocore, ibm_boto3\n# Reference:\n#   - Michael A. Nielsen, \"Neural Network & Deep Learning\",\n#     Determination Press, 2015 http://neuralnetworksanddeeplearning.com \n#     Original code from the book is at https://github.com/mnielsen/neural-networks-and-deep-learning\n#   - various references from stackoverflow, github, and related library documentations etc"
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# GET ALL REQUIRED FILES to working directory by using IBM boto3 api\n# Just need to do this once, comment afterward\n#\nimport sys\nimport types\nimport pandas as pd # dataframe manipulations\nfrom botocore.client import Config # to access IBM Object Storage\nimport ibm_boto3 # to access IBM Object Storage\n\n# LOAD required libraries\nimport matplotlib.pyplot as plt # graphic related things\nimport numpy as np # matrix manipulations\nimport math # math functions"
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Above cell is hidden for publishing... get your own key from IBM Watson Studio on IBM cloud to fill the following\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# replace \"your IBM API Key\" with your generated key\n# s3 = ibm_boto3.client(service_name='s3',\n#     ibm_api_key_id='your IBM API Key',\n#     ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n#     config=Config(signature_version='oauth'),\n#     endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')"
        }, 
        {
            "execution_count": 20, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# replace the following \"mybucket\" with your generated bucket\nmybucket='doctorofcomputerscience-donotdelete-pr-e1zj6xtk1pjpth'\n# 1. get mnist dataset\nwith open('mnist.pkl.gz', 'wb') as data:\n    s3.download_fileobj(mybucket, 'mnist.pkl.gz', data)\n# 2. get pyton library for loading mnist dataset\nwith open('mnist_loader_asm_py3.py', 'wb') as data:\n    s3.download_fileobj(mybucket, 'mnist_loader_asm_py3.py', data)\n# 3. get pyton library for training & prediction\nwith open('network2_asm_b_py3.py', 'wb') as data:\n    s3.download_fileobj(mybucket, 'network2_asm_b_py3.py', data)\n# file for testing to predict(), get pre-trained network (without retraining)\n# 2 hidden layers at 30 neurons each, lr=0.15, batch size=32, no regularization\n# result: train cost: 0.0609736142951, eval cost: 0.229741976137, train acc: 99.416 %, eval acc: 96.89 %\n# June 28 2018: Total time for 50 Epochs are: 681.4261889457703 seconds on IBM Cloud (1vCPU 4 GB RAM)\nwith open('2018624223944_asm_Trained_NN', 'wb') as data:\n    s3.download_fileobj(mybucket, '2018628165028_asm_Trained_NN', data)"
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# LOAD our specific libraries\nimport mnist_loader_asm_py3 # helper program for loading mnist data set\n# import network2_asm_b_py3 # helper program, neural network layers"
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#plot individual curve: training training/evaluation accuracy, training/evaluation cost\ndef plot_curve(xlabel, epoch, ylabel, loss):\n    # epoch: total epoch, loss: list of lost values for all epochs\n    epochs = []\n    for i in range(epoch):\n        epochs.append(i)\n    plt.plot(epochs,loss)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.show()\n    \n#compare training & evaluation accuracy / cost\ndef plot_curve_comparison(epoch, title, xlabel, data1, ylabel, data2):\n    epochs = []\n    for i in range(epoch):\n        epochs.append(i)\n    fig = plt.figure()\n    ax = plt.subplot(111)\n    ax.plot(epochs, data1, label=xlabel)\n    ax.plot(epochs, data2, label=ylabel)\n    plt.title(title)\n    ax.legend()\n    plt.show()\n\n# draw a 28x28 pixels digit from 784x1 input array\ndef draw_digit(input):\n    row = 1\n    column = 1\n    for i in range(column):\n        #get corresponding target label (y) \"digit\" from its vectorized format\n        #then, plot the image data \n        image = input.reshape(28, 28)   \n        plt.subplot(row, column, 1)  # subplot with size  \n        plt.imshow(image, cmap='gray')  # cmap='gray' is for black and white picture.\n        plt.axis('on')  # show axis value\n        plt.tight_layout()  # automatic padding between subplots\n        plt.show()"
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": ">> Training dataset (x, y)], length: 2 arrays.\n  - 1st array (data, x) 28x28 pixels; total data: 50000 , length per data: 784\n  - 2nd array (target label, y) [0..9]; total data: 50000\n    sample dataset: 5\n"
                }
            ], 
            "source": "# ========================\n# 1. LOAD Dataset (MNIST)\n# ========================\n# 1a. load mnist data using mnist_loader library\n#   output is structured in such a way to fit and be ready for learning\n#   each data is in 784x1 dimension, reshape to 28x28 pixels for viewing\n#   each label is in 8x1 dimension,\n#     extract array content with \"1\" in it to get the actual label [\"0\"..\"9\"]\n#\nzip_training_data, zip_validation_data, zip_test_data = mnist_loader_asm_py3.load_data_wrapper()"
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "training_data = list(zip_training_data)\nvalidation_data = list(zip_validation_data)\ntest_data = list(zip_test_data)"
        }, 
        {
            "execution_count": 25, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "A few samples for the 28x28 pixels mnist digit dataset with its corresponding label\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7f3f647cfc18>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7f3f912ab898>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7f3f64723630>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "# 1b. just show a few sample digits with its corresponding labels\n#\nprint(\"A few samples for the 28x28 pixels mnist digit dataset with its corresponding label\")\nrow = 1\ncolumn = 3\nnp.random.shuffle(training_data) # just resuffle so we are showing different data when refreshed\nfor i in range(column):\n    #get corresponding target label (y) \"digit\" from its vectorized format\n    data = training_data[i][1]\n    digit=0\n    j=0\n    for x in data:\n        if int(x):\n            digit=j\n            break\n        else:\n            j=j+1\n    #then, plot the image data \n    image = training_data[i][0].reshape(28, 28)   \n    plt.subplot(row, column, i+1)  # subplot with size  \n    plt.imshow(image, cmap='gray')  # cmap='gray' is for black and white picture.\n    plt.title('labelled as = {0}'.format(digit))\n    plt.axis('on')  # do not show axis value\n    plt.tight_layout()  # automatic padding between subplots\n    filename = \"mnist_plot\"+str(i)+\".png\"\n    plt.savefig(filename)\n    plt.show()"
        }, 
        {
            "execution_count": 26, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(784, 1)\n(10, 1)\n"
                }
            ], 
            "source": "# x_train\nprint(training_data[0][0].shape)\n# y_train\nprint(training_data[0][1].shape)"
        }, 
        {
            "execution_count": 27, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "training_data_ndarray = np.array(training_data)\n# xtmp_train, ytmp_train (temporary before adjusted for keras)\nxtmp_train, ytmp_train = training_data_ndarray[:, :-1], training_data_ndarray[:, -1]\n# print(xtmp_train.shape, xtmp_train[0][0].shape)\n# print(ytmp_train.shape, ytmp_train[0].shape)"
        }, 
        {
            "execution_count": 28, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# preparing x_train \"x\" data to be suitable for input to keras framework (for training)\n# with dimension 50,000 x 784\n# x_train will be ready for Keras.Dense layer\ni=0\nrow=len(xtmp_train)\ncolumn=len(xtmp_train[0][0])\n# print(row, column)\nx_train = np.zeros((row, column))\n# print(x_train.shape)\nwhile(i<(len(xtmp_train)-1)):\n    x_train[i] = np.reshape(xtmp_train[i][0], (1,784))\n    i=i+1\n\nx_train = x_train.reshape(row, 28, 28, 1) # Preparing x_train to be ready for Keras.Conv2D layer\n    \n# preparing y_train \"y\" data to be suitable for input to keras framework (for training)\n# with dimension 50,000 x 10\ni=0\nrow=len(ytmp_train)\ncolumn=len(ytmp_train[0])\n# print(row, column)\ny_train = np.zeros((row, column))\n# print(y_train.shape)\nwhile(i<(len(ytmp_train)-1)):\n    y_train[i] = np.reshape(ytmp_train[i], (1,10))\n    i=i+1"
        }, 
        {
            "execution_count": 29, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(50000, 28, 28, 1)\n"
                }
            ], 
            "source": "print(x_train.shape)"
        }, 
        {
            "execution_count": 30, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# July 14 2018: use keras framework with default: tensorflow\n# create VGG-like network, see https://keras.io/layers/convolutional/\nimport keras \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n\nmodel = Sequential()\n#input layer with 784 neurons arranged in 28x28, with 1st hidden layer as Conv2D\nmodel.add(Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\nmodel.add(Conv2D(32, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25)) \n\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25)) \n\nmodel.add(Flatten())\nmodel.add(Dense(units=256, activation='relu'))\nmodel.add(Dropout(0.5)) \n\n# output layer, 10 neurons (digits 0..9)\nmodel.add(Dense(units=10, activation='softmax'))\n          \nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))"
        }, 
        {
            "execution_count": 31, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 24, 24, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 12, 12, 32)        0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 12, 12, 32)        0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 10, 10, 64)        18496     \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 8, 8, 64)          36928     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 4, 4, 64)          0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 1024)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 256)               262400    \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 10)                2570      \n=================================================================\nTotal params: 329,962\nTrainable params: 329,962\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
                }
            ], 
            "source": "print(model.summary())"
        }, 
        {
            "execution_count": 32, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(50000, 28, 28, 1) (50000, 10)\n"
                }
            ], 
            "source": "# our x_train and y_train in numpy.ndarray format that are now ready as expected by keras framework\nprint(x_train.shape, y_train.shape)"
        }, 
        {
            "execution_count": 33, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Epoch 1/10\n50000/50000 [==============================] - 319s 6ms/step - loss: 0.2964\nEpoch 2/10\n50000/50000 [==============================] - 323s 6ms/step - loss: 0.0924\nEpoch 3/10\n50000/50000 [==============================] - 321s 6ms/step - loss: 0.0642\nEpoch 4/10\n50000/50000 [==============================] - 325s 6ms/step - loss: 0.0566\nEpoch 5/10\n50000/50000 [==============================] - 326s 7ms/step - loss: 0.0490\nEpoch 6/10\n50000/50000 [==============================] - 326s 7ms/step - loss: 0.0425\nEpoch 7/10\n50000/50000 [==============================] - 322s 6ms/step - loss: 0.0382\nEpoch 8/10\n50000/50000 [==============================] - 322s 6ms/step - loss: 0.0364\nEpoch 9/10\n50000/50000 [==============================] - 319s 6ms/step - loss: 0.0308\nEpoch 10/10\n50000/50000 [==============================] - 320s 6ms/step - loss: 0.0311\n"
                }, 
                {
                    "execution_count": 33, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x7f3f5d77f550>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# # ==================================================\n# # 2. TRAIN the Neural Network (SUPERVISED LEARNING)\n# # ==================================================\nmodel.fit(x_train, y_train, epochs=10, batch_size=32)"
        }, 
        {
            "execution_count": 34, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "saving: 2018714195532_asm_Trained_NN_Keras_Conv2D ...\ndone.\n"
                }
            ], 
            "source": "# 2b. save the last trained network sizes, weights, biases, cost\n#\n# generate current time to be embedded in filename\nimport time\ndt = time.localtime(time.time())\ni=0\nprefix = \"\"\nwhile i<6:\n    #print str(dt[i])\n    prefix = prefix + str(dt[i])\n    i=i+1\n# embed the current time in file name\nfilename = prefix + \"_asm_Trained_NN_Keras_Conv2D\"\nprint(\"saving:\", filename, \"...\")\nmodel.save_weights(filename)\nprint(\"done.\")"
        }, 
        {
            "execution_count": 35, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# # 2c. load trained network for prediction\n# # e.g. filename = 2018714195532_asm_Trained_NN_Keras_Conv2D\n# filename = 2018714195532_asm_Trained_NN_Keras_Conv2D\n# print(\"loading:\", filename, \"...\")\n# model.load_weights(filename)\n# print(\"done.\")"
        }, 
        {
            "execution_count": 36, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(10000, 784)\n(10000, 28, 28, 1)\n"
                }
            ], 
            "source": "# preparing test_data suitable for input to keras framework (for prediction)\n# with dimension 10,000 x 784\n# x_test will be ready for Keras.Dense layer\ntest_data_ndarray = np.array(test_data)\nxtmp_data, ytmp_data = test_data_ndarray[:, :-1], test_data_ndarray[:, -1]\nrow=len(test_data_ndarray)\ncolumn=len(test_data_ndarray[0][0])\n# print(row, column)\nx_test_data = np.zeros((row, column))\ni=0\nwhile(i<row-1):\n    x_test_data[i] = xtmp_data[i][0].reshape(1,784)\n    i=i+1\nprint(x_test_data.shape)\n\n# Preparing x_test to be ready for Keras.Conv2D layer\nx_test_data = x_test_data.reshape(row, 28, 28, 1)\nprint(x_test_data.shape)"
        }, 
        {
            "execution_count": 37, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "test_data index = 9365\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7f3f65c643c8>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "running digit prediction...\n1/1 [==============================] - 0s 23ms/step\nlabeled as:  3\nrecognized as:  3\n"
                }
            ], 
            "source": "# # =========== \n# # 3. PREDICT\n# # =========== \nimport random\nrandom_value = random.randint(0, row-1)\n# print(x_test_data[random_value].shape)\ny_test_data = test_data_ndarray[random_value][1]\nprint(\"test_data index =\", random_value)\nimage = x_test_data[random_value]\ndraw_digit(image)\nprint(\"running digit prediction...\")\nresult = model.predict(image.reshape(1,28,28,1), batch_size=None, verbose=1, steps=None)\nprint(\"labeled as: \", y_test_data)\nprint(\"recognized as: \", np.argmax(result))"
        }, 
        {
            "execution_count": 38, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# upload the trained data to IBM Object Storage\nwith open(filename, 'rb') as data:\n    s3.upload_fileobj(data, mybucket, filename)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!ls -al"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}