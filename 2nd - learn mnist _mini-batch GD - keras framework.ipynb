{
    "nbformat_minor": 2, 
    "cells": [
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Author: Andi Sama\n# Organization: Sinergi Wahana Gemilang\n#   a Value Added Distributor in Jakarta, Indonesia\n# Created: June 18, 2018\n# Last modified:\n#   - June 19, 2018\n#     * Add a few more information during training by modifying code in network_asm.py\n#       (% on classification rate & elapsed time per epoch + total elapsed time for all epochs)\n#     * Add a few more information during training by modifying code in mnist_loader_asm.py\n#       (loaded data sizes)\n#   - June 21, 2018\n#     * Apply cross-entropy on cost function (previously: use quadratic cost) to improve accuracy\n#     * Apply Mini-batch gradient descent (previously: just Stochastic Gradient Descent)\n#     * Add monitor_elapsed_time flag in network2_asm.py\n#     * Draw plot for training cost, evaluation cost against # of epoch\n#     * Use Gaussian distributions with mean 0 and standard deviation 1 over the square root\n#       of the number of weights connecting to the same neuron for network initialization\n#       (previously: Gaussian distribution without square root)\n#   - June 23, 2018\n#     * Use regularization - lambda \n#     * Visualization of mnist dataset\n#   - June 24, 2018\n#       Add predict() function use existing function load() network after save()\n#       => vanilla version done\n#   - June 24, 2018\n#     * use mnist testing dataset to predict (now still using training data)\n#   - June 25-26, 2018\n#     * migrate to IBM Watson Studio (on cloud)\n#       - upload all files to IBM object storage\n#       - get all files to working directory by using IBM boto3 api\n#       - convert code from python 2.7 to 3.5 (print function, cPickle handler, xrange)\n#   - June 28, 2018\n#     retrain with lambda = 0 (no regularization, for article - for SWG Insights Q4 2018)\n#   - July 9-12, 2018\n#     change framework to keras (change MNIST input to numpy.ndarray)\n# Topic: Beginning Deep Learning (computer vision)\n# Purpose: Recognizing handwritten digits 0-9 in 3 steps\n#   - 1. Prepare datasets (MNIST, modified nist database)\n#   - 2. Train, Validate on datasets to generate deep learning model (architecture, weights)\n#   - 3. Predict new data based on generated model with testing data \n# Type of Neural Network: Supervised Learning with shallow neural network\n#   Dataset: mnist\n#     - original training dataset (60,000): handwritten digits from 250 persons (2 groups)\n#       further then divided to be 50,000 for training dataset and 10,000 for validation dataset\n#     - testing dataset (10,000): handwritten digits from another set of 250 persons (2 groups)\n# Hardware & Software platforms:\n#   - environment: cygwin on Windows, on Thinkpad T450 (i7 4 vCPUs without GPUs, 16 GB RAM)\n#   - programming language: python (v2.7)\n#   - deep learning framework: none\n#   - libraries: sys, pandas, numpy, math, matplotlib, botocore, ibm_boto3\n# Reference:\n#   - Michael A. Nielsen, \"Neural Network & Deep Learning\",\n#     Determination Press, 2015 http://neuralnetworksanddeeplearning.com \n#     Original code from the book is at https://github.com/mnielsen/neural-networks-and-deep-learning\n#   - various references from stackoverflow, github, and related library documentations etc"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# GET ALL REQUIRED FILES to working directory by using IBM boto3 api\n# Just need to do this once, comment afterward\n#\nimport sys\nimport types\nimport pandas as pd # dataframe manipulations\nfrom botocore.client import Config # to access IBM Object Storage\nimport ibm_boto3 # to access IBM Object Storage\n\n# LOAD required libraries\nimport matplotlib.pyplot as plt # graphic related things\nimport numpy as np # matrix manipulations\nimport math # math functions"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Above cell is hidden for publishing... get your own key from IBM Watson Studio on IBM cloud to fill the following\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# replace \"your IBM API Key\" with your generated key\n# s3 = ibm_boto3.client(service_name='s3',\n#     ibm_api_key_id='your IBM API Key',\n#     ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n#     config=Config(signature_version='oauth'),\n#     endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# replace the following \"mybucket\" with your generated bucket\nmybucket='doctorofcomputerscience-donotdelete-pr-e1zj6xtk1pjpth'\n# 1. get mnist dataset\nwith open('mnist.pkl.gz', 'wb') as data:\n    s3.download_fileobj(mybucket, 'mnist.pkl.gz', data)\n# 2. get pyton library for loading mnist dataset\nwith open('mnist_loader_asm_py3.py', 'wb') as data:\n    s3.download_fileobj(mybucket, 'mnist_loader_asm_py3.py', data)\n# 3. get pyton library for training & prediction\nwith open('network2_asm_b_py3.py', 'wb') as data:\n    s3.download_fileobj(mybucket, 'network2_asm_b_py3.py', data)\n# file for testing to predict(), get pre-trained network (without retraining)\n# 2 hidden layers at 30 neurons each, lr=0.15, batch size=32, no regularization\n# result: train cost: 0.0609736142951, eval cost: 0.229741976137, train acc: 99.416 %, eval acc: 96.89 %\n# June 28 2018: Total time for 50 Epochs are: 681.4261889457703 seconds on IBM Cloud (1vCPU 4 GB RAM)\nwith open('2018624223944_asm_Trained_NN', 'wb') as data:\n    s3.download_fileobj(mybucket, '2018628165028_asm_Trained_NN', data)"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# LOAD our specific libraries\nimport mnist_loader_asm_py3 # helper program for loading mnist data set\n# import network2_asm_b_py3 # helper program, neural network layers"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#plot individual curve: training training/evaluation accuracy, training/evaluation cost\ndef plot_curve(xlabel, epoch, ylabel, loss):\n    # epoch: total epoch, loss: list of lost values for all epochs\n    epochs = []\n    for i in range(epoch):\n        epochs.append(i)\n    plt.plot(epochs,loss)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.show()\n    \n#compare training & evaluation accuracy / cost\ndef plot_curve_comparison(epoch, title, xlabel, data1, ylabel, data2):\n    epochs = []\n    for i in range(epoch):\n        epochs.append(i)\n    fig = plt.figure()\n    ax = plt.subplot(111)\n    ax.plot(epochs, data1, label=xlabel)\n    ax.plot(epochs, data2, label=ylabel)\n    plt.title(title)\n    ax.legend()\n    plt.show()\n\n# draw a 28x28 pixels digit from 784x1 input array\ndef draw_digit(input):\n    row = 1\n    column = 1\n    for i in range(column):\n        #get corresponding target label (y) \"digit\" from its vectorized format\n        #then, plot the image data \n        image = input.reshape(28, 28)   \n        plt.subplot(row, column, 1)  # subplot with size  \n        plt.imshow(image, cmap='gray')  # cmap='gray' is for black and white picture.\n        plt.axis('on')  # show axis value\n        plt.tight_layout()  # automatic padding between subplots\n        plt.show()"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": ">> Training dataset (x, y)], length: 2 arrays.\n  - 1st array (data, x) 28x28 pixels; total data: 50000 , length per data: 784\n  - 2nd array (target label, y) [0..9]; total data: 50000\n    sample dataset: 5\n"
                }
            ], 
            "source": "# ========================\n# 1. LOAD Dataset (MNIST)\n# ========================\n# 1a. load mnist data using mnist_loader library\n#   output is structured in such a way to fit and be ready for learning\n#   each data is in 784x1 dimension, reshape to 28x28 pixels for viewing\n#   each label is in 8x1 dimension,\n#     extract array content with \"1\" in it to get the actual label [\"0\"..\"9\"]\n#\nzip_training_data, zip_validation_data, zip_test_data = mnist_loader_asm_py3.load_data_wrapper()"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "training_data = list(zip_training_data)\nvalidation_data = list(zip_validation_data)\ntest_data = list(zip_test_data)"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "A few samples for the 28x28 pixels mnist digit dataset with its corresponding label\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7f368074acf8>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7f368073d9b0>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7f3680053128>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "# 1b. just show a few sample digits with its corresponding labels\n#\nprint(\"A few samples for the 28x28 pixels mnist digit dataset with its corresponding label\")\nrow = 1\ncolumn = 3\nnp.random.shuffle(training_data) # just resuffle so we are showing different data when refreshed\nfor i in range(column):\n    #get corresponding target label (y) \"digit\" from its vectorized format\n    data = training_data[i][1]\n    digit=0\n    j=0\n    for x in data:\n        if int(x):\n            digit=j\n            break\n        else:\n            j=j+1\n    #then, plot the image data \n    image = training_data[i][0].reshape(28, 28)   \n    plt.subplot(row, column, i+1)  # subplot with size  \n    plt.imshow(image, cmap='gray')  # cmap='gray' is for black and white picture.\n    plt.title('labelled as = {0}'.format(digit))\n    plt.axis('on')  # do not show axis value\n    plt.tight_layout()  # automatic padding between subplots\n    filename = \"mnist_plot\"+str(i)+\".png\"\n    plt.savefig(filename)\n    plt.show()"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(784, 1)\n(10, 1)\n"
                }
            ], 
            "source": "# x_train\nprint(training_data[0][0].shape)\n# y_train\nprint(training_data[0][1].shape)"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "training_data_ndarray = np.array(training_data)\n# xtmp_train, ytmp_train (temporary before adjusted for keras)\nxtmp_train, ytmp_train = training_data_ndarray[:, :-1], training_data_ndarray[:, -1]\n# print(xtmp_train.shape, xtmp_train[0][0].shape)\n# print(ytmp_train.shape, ytmp_train[0].shape)"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# preparing x_train \"x\" data to be suitable for input to keras framework (for training)\n# with dimension 50,000 x 784\ni=0\nrow=len(xtmp_train)\ncolumn=len(xtmp_train[0][0])\n# print(row, column)\nx_train = np.zeros((row, column))\n# print(x_train.shape)\nwhile(i<(len(xtmp_train)-1)):\n    x_train[i] = np.reshape(xtmp_train[i][0], (1,784))\n    i=i+1\n    \n# preparing y_train \"y\" data to be suitable for input to keras framework (for training)\n# with dimension 50,000 x 10\ni=0\nrow=len(ytmp_train)\ncolumn=len(ytmp_train[0])\n# print(row, column)\ny_train = np.zeros((row, column))\n# print(y_train.shape)\nwhile(i<(len(ytmp_train)-1)):\n    y_train[i] = np.reshape(ytmp_train[i], (1,10))\n    i=i+1"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "source": "# July 9-12 2018: use keras framework with default: tensorflow as backend, instead of pure python code\nimport keras \nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nmodel = Sequential()\n#input layer with 784 neurons, 1st hidden layer with 30 neurons\nmodel.add(Dense(units=30, activation='relu', input_dim=784))\n# 2nd hidden layer, 30 neurons\nmodel.add(Dense(units=30, activation='relu'))\n# output layer, 10 neurons (digits 0..9)\nmodel.add(Dense(units=10, activation='softmax'))  \nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(50000, 784) (50000, 10)\n"
                }
            ], 
            "source": "# our x_train and y_train in numpy.ndarray format that are now ready as expected by keras framework\nprint(x_train.shape, y_train.shape)"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 30)                23550     \n_________________________________________________________________\ndense_2 (Dense)              (None, 30)                930       \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                310       \n=================================================================\nTotal params: 24,790\nTrainable params: 24,790\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ], 
            "source": "model.summary()"
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Epoch 1/50\n50000/50000 [==============================] - 6s 115us/step - loss: 0.3693\nEpoch 2/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.1797\nEpoch 3/50\n50000/50000 [==============================] - 6s 112us/step - loss: 0.1439\nEpoch 4/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.1259\nEpoch 5/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.1089\nEpoch 6/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0980\nEpoch 7/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0918\nEpoch 8/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0825\nEpoch 9/50\n50000/50000 [==============================] - 6s 112us/step - loss: 0.0772\nEpoch 10/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0723\nEpoch 11/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0673\nEpoch 12/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0631\nEpoch 13/50\n50000/50000 [==============================] - 6s 113us/step - loss: 0.0587\nEpoch 14/50\n50000/50000 [==============================] - 6s 112us/step - loss: 0.0575\nEpoch 15/50\n50000/50000 [==============================] - 6s 112us/step - loss: 0.0523\nEpoch 16/50\n50000/50000 [==============================] - 6s 112us/step - loss: 0.0534\nEpoch 17/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0480\nEpoch 18/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0456 0s - loss: 0.045\nEpoch 19/50\n50000/50000 [==============================] - 6s 113us/step - loss: 0.0452\nEpoch 20/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0441\nEpoch 21/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0434\nEpoch 22/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0373\nEpoch 23/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0380\nEpoch 24/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0350\nEpoch 25/50\n50000/50000 [==============================] - 6s 113us/step - loss: 0.0312\nEpoch 26/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0315\nEpoch 27/50\n50000/50000 [==============================] - 6s 112us/step - loss: 0.0334\nEpoch 28/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0348\nEpoch 29/50\n50000/50000 [==============================] - 6s 116us/step - loss: 0.0321\nEpoch 30/50\n50000/50000 [==============================] - 6s 113us/step - loss: 0.0328\nEpoch 31/50\n50000/50000 [==============================] - 6s 116us/step - loss: 0.0290\nEpoch 32/50\n50000/50000 [==============================] - 6s 115us/step - loss: 0.0257\nEpoch 33/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0275\nEpoch 34/50\n50000/50000 [==============================] - 6s 112us/step - loss: 0.0275\nEpoch 35/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0279\nEpoch 36/50\n50000/50000 [==============================] - 6s 116us/step - loss: 0.0264\nEpoch 37/50\n50000/50000 [==============================] - 6s 112us/step - loss: 0.0256\nEpoch 38/50\n50000/50000 [==============================] - 6s 116us/step - loss: 0.0276\nEpoch 39/50\n50000/50000 [==============================] - 6s 113us/step - loss: 0.0260\nEpoch 40/50\n50000/50000 [==============================] - 6s 115us/step - loss: 0.0215\nEpoch 41/50\n50000/50000 [==============================] - 6s 112us/step - loss: 0.0225\nEpoch 42/50\n50000/50000 [==============================] - 6s 115us/step - loss: 0.0264\nEpoch 43/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0210\nEpoch 44/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0194\nEpoch 45/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0254\nEpoch 46/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0254\nEpoch 47/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0201\nEpoch 48/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0191\nEpoch 49/50\n50000/50000 [==============================] - 6s 114us/step - loss: 0.0208\nEpoch 50/50\n50000/50000 [==============================] - 6s 115us/step - loss: 0.0207\n"
                }, 
                {
                    "execution_count": 17, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x7f3657a25f28>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# # ==================================================\n# # 2. TRAIN the Neural Network (SUPERVISED LEARNING)\n# # ==================================================\nmodel.fit(x_train, y_train, epochs=50, batch_size=32)"
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "saving: 201871275844_asm_Trained_NN_Keras ...\ndone.\n"
                }
            ], 
            "source": "# 2b. save the last trained network sizes, weights, biases, cost\n#\n# generate current time to be embedded in filename\nimport time\ndt = time.localtime(time.time())\ni=0\nprefix = \"\"\nwhile i<6:\n    #print str(dt[i])\n    prefix = prefix + str(dt[i])\n    i=i+1\n# embed the current time in file name\nfilename = prefix + \"_asm_Trained_NN_Keras\"\nprint(\"saving:\", filename, \"...\")\nmodel.save_weights(filename)\nprint(\"done.\")"
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# # 2c. load trained network for prediction\n# # e.g. filename = 2018710121134_asm_Trained_NN_Keras\n# filename = 2018710121134_asm_Trained_NN_Keras\n# print(\"saving:\", filename, \"...\")\n# model.load_weights(filename)\n# print(\"done.\")"
        }, 
        {
            "execution_count": 20, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(10000, 784)\n"
                }
            ], 
            "source": "# preparing test_data suitable for input to keras framework (for prediction)\n# with dimension 10,000 x 784\ntest_data_ndarray = np.array(test_data)\nxtmp_data, ytmp_data = test_data_ndarray[:, :-1], test_data_ndarray[:, -1]\nrow=len(test_data_ndarray)\ncolumn=len(test_data_ndarray[0][0])\n# print(row, column)\nx_test_data = np.zeros((row, column))\ni=0\nwhile(i<row-1):\n    x_test_data[i] = xtmp_data[i][0].reshape(1,784)\n    i=i+1\nprint(x_test_data.shape)"
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "test_data index = 5624\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7f3656f23898>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "running digit prediction...\n1/1 [==============================] - 0s 8ms/step\nlabeled as:  5\nrecognized as:  5\n"
                }
            ], 
            "source": "# # =========== \n# # 3. PREDICT\n# # =========== \nimport random\nrandom_value = random.randint(0, row-1)\n# print(x_test_data[random_value].shape)\ny_test_data = test_data_ndarray[random_value][1]\nprint(\"test_data index =\", random_value)\nimage = x_test_data[random_value]\ndraw_digit(image)\nprint(\"running digit prediction...\")\nresult = model.predict(image.reshape(1,784), batch_size=None, verbose=1, steps=None)\nprint(\"labeled as: \", y_test_data)\nprint(\"recognized as: \", np.argmax(result))"
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# upload the trained data to IBM Object Storage\nwith open(filename, 'rb') as data:\n    s3.upload_fileobj(data, mybucket, filename)"
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "total 17352\r\ndrwxr-x--- 3 dsxuser dsxuser     4096 Jul 12 07:58 .\r\ndrwx------ 1 dsxuser dsxuser     4096 Jul 12 05:55 ..\r\n-rw-r----- 1 dsxuser dsxuser   531635 Jul 12 07:53 2018624223944_asm_Trained_NN\r\n-rw-r----- 1 dsxuser dsxuser   113608 Jul 12 07:58 201871275844_asm_Trained_NN_Keras\r\n-rw-r----- 1 dsxuser dsxuser     4672 Jul 12 07:53 mnist_loader_asm_py3.py\r\n-rw-r----- 1 dsxuser dsxuser 17051982 Jul 12 07:53 mnist.pkl.gz\r\n-rw-r----- 1 dsxuser dsxuser     5406 Jul 12 07:53 mnist_plot0.png\r\n-rw-r----- 1 dsxuser dsxuser     4978 Jul 12 07:53 mnist_plot1.png\r\n-rw-r----- 1 dsxuser dsxuser     5108 Jul 12 07:53 mnist_plot2.png\r\n-rw-r----- 1 dsxuser dsxuser    16404 Jul 12 07:53 network2_asm_b_py3.py\r\ndrwxr-x--- 2 dsxuser dsxuser     4096 Jul 12 07:53 __pycache__\r\n"
                }
            ], 
            "source": "!ls -al"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}